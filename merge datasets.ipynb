{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import os\n",
    "from transliterate import translit, get_available_language_codes\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = r'C:\\Users\\m.lavreniuk\\Downloads\\tasks_new'\n",
    "dst = r'C:\\Users\\m.lavreniuk\\Downloads\\rr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_index_map(root, d):\n",
    "    label_name_dict = {}\n",
    "    path_to_names = os.path.join(root, d, 'obj.names')\n",
    "    #with open(path_to_names, 'r') as f:\n",
    "    with codecs.open(path_to_names, \"r\", encoding='utf-8') as f:\n",
    "\n",
    "        names = f.read().splitlines()\n",
    "    for i, n in enumerate(names):\n",
    "        label_name_dict[str(i)] = n\n",
    "\n",
    "    return label_name_dict\n",
    "\n",
    "\n",
    "def get_pathes_to_txt(root, d):\n",
    "    num_txt = 0\n",
    "    for root2, dirs2, files2 in os.walk(os.path.join(root, d, 'obj_train_data')):\n",
    "        for d2 in dirs2:\n",
    "            path_to_annotations = os.path.join(root2, d2)\n",
    "            pathes_to_txt = glob(os.path.join(path_to_annotations, '*.txt'))\n",
    "            num_txt += len(pathes_to_txt)\n",
    "            \n",
    "    return pathes_to_txt, num_txt\n",
    "    \n",
    "import codecs\n",
    "\n",
    "\n",
    "def count_labels(root, d, task_index_map, labels_counter):\n",
    "    num_objects = 0\n",
    "    num_fotos = 0\n",
    "    p, num_txt = get_pathes_to_txt(root, d)\n",
    "    for t in p:\n",
    "        with open(t, 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "            if len(lines) != 0:\n",
    "                num_fotos += 1\n",
    "            for l in lines:\n",
    "                label_id = l.split(' ')[0]\n",
    "                name = task_index_map[label_id]\n",
    "                labels_counter[name] += 1\n",
    "                num_objects += 1\n",
    "                \n",
    "    return labels_counter, num_objects, num_fotos, num_txt\n",
    "                \n",
    "    \n",
    "def get_stats(src):\n",
    "    labels_counter = defaultdict(int)\n",
    "    task_maps = {}\n",
    "    for root, dirs, files in os.walk(src, topdown = True):\n",
    "        for d in dirs:\n",
    "            index_map = get_task_index_map(root, d)\n",
    "            task_maps[d] = index_map\n",
    "            labels_counter, num_objects, num_fotos, num_txt = \\\n",
    "            count_labels(root, d, index_map, labels_counter)            \n",
    "        break\n",
    "    return labels_counter, task_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'buljon_kur_bol': 501,\n",
       "             'sup_grech_mal': 425,\n",
       "             'sup_soljanka_mal': 451,\n",
       "             'ovosch_zapech': 432,\n",
       "             'kotl_kur': 395,\n",
       "             'sal_cesar': 406,\n",
       "             'adjapsandali': 367,\n",
       "             'sal_s_tuncom': 360,\n",
       "             'kapusta_tush': 388,\n",
       "             'tefteli_mjasn': 390,\n",
       "             'ljulja_kebab': 968,\n",
       "             'befstrog_kur': 560,\n",
       "             'gribi_v_smet': 426,\n",
       "             'kasha_kukuruz': 422,\n",
       "             'borsch_mal': 434,\n",
       "             'bitok_svin': 895,\n",
       "             'baget_belij': 515,\n",
       "             'seld_pod_shub': 500,\n",
       "             'harcho_bol': 434,\n",
       "             'sal_grech': 500})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter, task_maps = get_stats(src)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(counter, orient='index', columns=['count'])\n",
    "df = df.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 150\n",
    "a = df.loc[df['count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(a.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_label_map = { } \n",
    "for i, l in enumerate(labels):\n",
    "    global_label_map[l] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_label_map = {'kotl_indejka': 9,\n",
    " 'sup_soljanka_mal': 10,\n",
    " 'ljulja_kebab': 11,\n",
    " 'sal_sparj': 12,\n",
    " 'sup_ovoschnoj_bol': 13,\n",
    " 'hleb_chernij': 14,\n",
    " 'bitok_svin': 15,\n",
    " 'fasol_s_ovoschami': 16,\n",
    " 'buljon_kur_bol': 17,\n",
    " 'kartofel_pech': 18,\n",
    " 'sal_vegan_kinoa': 19,\n",
    " 'ovosch_gril': 20,\n",
    " 'ovosch_zapech': 21,\n",
    " 'sal_morkovka_korejskaja': 22,\n",
    " 'sup_grech_mal': 23,\n",
    " 'befstrog_kur': 24,\n",
    " 'baget_belij': 25,\n",
    " 'sal_grech': 26,\n",
    " 'seld_pod_shub': 27,\n",
    " 'sal_cesar': 28,\n",
    " 'kotl_kur': 29,\n",
    " 'kapusta_tush': 30,\n",
    " 'adjapsandali': 31,\n",
    " 'tefteli_mjasn': 32,\n",
    " 'sal_s_tuncom': 33,\n",
    " 'sup_soljanka_bol': 34,\n",
    " 'borsch_mal': 2,\n",
    " 'gribi_v_smet': 35,\n",
    " 'kasha_kukuruz': 36,\n",
    " 'harcho_bol': 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_kur_otvarn\n",
      "ljulja_kebab\n",
      "bitok_svin\n",
      "buljon_kur_bol\n",
      "sup_borsch_bol\n",
      "befstrog_kur\n",
      "baget_grech\n",
      "ris\n",
      "sup_soljanka_mal\n",
      "ovosch_osen\n",
      "baget_belij\n",
      "ovosch_zapech\n",
      "sup_ovosch_mal\n",
      "sup_grech_mal\n",
      "sal_grech\n",
      "seld_pod_shub\n",
      "sal_cesar\n",
      "kotl_kur\n",
      "tefteli_mjasn\n",
      "kapusta_tush\n",
      "adjapsandali\n",
      "sal_s_tuncom\n",
      "sal_jugnobursk\n",
      "sup_grech_bol\n",
      "sal_negnost\n",
      "gribi_v_smet\n",
      "harcho_bol\n",
      "kasha_kukuruz\n",
      "borsch_mal\n"
     ]
    }
   ],
   "source": [
    "for i in global_label_map.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ljulja_kebab': 0,\n",
       " 'bitok_svin': 1,\n",
       " 'befstrog_kur': 2,\n",
       " 'baget_belij': 3,\n",
       " 'buljon_kur_bol': 4,\n",
       " 'seld_pod_shub': 5,\n",
       " 'sal_grech': 6,\n",
       " 'sup_soljanka_mal': 7,\n",
       " 'borsch_mal': 8,\n",
       " 'harcho_bol': 9,\n",
       " 'ovosch_zapech': 10,\n",
       " 'gribi_v_smet': 11,\n",
       " 'sup_grech_mal': 12,\n",
       " 'kasha_kukuruz': 13,\n",
       " 'sal_cesar': 14,\n",
       " 'kotl_kur': 15,\n",
       " 'tefteli_mjasn': 16,\n",
       " 'kapusta_tush': 17,\n",
       " 'adjapsandali': 18,\n",
       " 'sal_s_tuncom': 19}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_names(label_map):\n",
    "    tr_names = [translit(key, reversed=True).replace(\"'\", \"\").replace(\"SR\", \"\") for key in list(global_label_map.keys())]\n",
    "    with open(os.path.join(dst, 'obj.names'), 'w') as f:\n",
    "        [f.write(l + '\\n') for l in tr_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "LanguageDetectionError",
     "evalue": "Can't detect language for the text \"kotl_indejka\" given.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLanguageDetectionError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c57ff6667961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwrite_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_label_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-d9331e7c457b>\u001b[0m in \u001b[0;36mwrite_names\u001b[1;34m(label_map)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtr_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtranslit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_label_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'obj.names'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtr_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-d9331e7c457b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtr_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtranslit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_label_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'obj.names'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtr_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transliterate\\utils.py\u001b[0m in \u001b[0;36mtranslit\u001b[1;34m(value, language_code, reversed, strict)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlanguage_code\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mlanguage_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfail_silently\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transliterate\\utils.py\u001b[0m in \u001b[0;36mdetect_language\u001b[1;34m(text, num_words, fail_silently, heavy_check)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfail_silently\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         raise LanguageDetectionError(\n\u001b[0m\u001b[0;32m    221\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"Can't detect language for the text \"%s\" given.\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         )\n",
      "\u001b[1;31mLanguageDetectionError\u001b[0m: Can't detect language for the text \"kotl_indejka\" given."
     ]
    }
   ],
   "source": [
    "write_names(global_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lines(lines):\n",
    "    new_lines = []\n",
    "    for l in lines:\n",
    "        l_splited = l.split(' ')\n",
    "        label_id = l_splited[0]\n",
    "        name = task_index_map[label_id]\n",
    "        try:\n",
    "            new_label_id = global_label_map[name]\n",
    "        except KeyError as e:\n",
    "            continue\n",
    "        else:\n",
    "            l_splited[0] = str(new_label_id)\n",
    "            l_new = ' '.join(l_splited)\n",
    "            new_lines.append(l_new)\n",
    "            \n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skiped_num=0\n"
     ]
    }
   ],
   "source": [
    "skiped_num = 0\n",
    "path_to_images = os.path.join(dst, 'images')\n",
    "path_to_labels = os.path.join(dst, 'labels')\n",
    "for root, dirs, files in os.walk(src, topdown = True):\n",
    "    for d in dirs:\n",
    "        task_index_map = task_maps[d] \n",
    "        pathes, _ = get_pathes_to_txt(root, d)\n",
    "        for t in pathes:\n",
    "            with open(t, 'r') as f:\n",
    "                lines = f.read().splitlines()\n",
    "                new_lines = convert_lines(lines)                \n",
    "            image_path = t.replace(\".txt\", \".jpg\")\n",
    "            if not os.path.exists(image_path):\n",
    "                skiped_num += 1\n",
    "            else:\n",
    "                pass\n",
    "                #copy(image_path, path_to_images)\n",
    "            path_txt = os.path.join(path_to_labels, os.path.basename(t))\n",
    "            path_txt = t\n",
    "            with open(path_txt, 'w') as f:\n",
    "                f.writelines(s + '\\n' for s in new_lines)\n",
    "    break\n",
    "    \n",
    "print(f'{skiped_num=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sal_vegan_kinoa',\n",
       " 'sal_morkovka_korejskaja',\n",
       " 'ovosch_gril',\n",
       " 'kotl_indejka',\n",
       " 'sup_soljanka_bol',\n",
       " 'fasol_s_ovoschami',\n",
       " 'sal_sparj',\n",
       " 'kartofel_pech',\n",
       " 'sup_ovoschnoj_bol',\n",
       " 'hleb_chernij',\n",
       " 'kotl_idejka',\n",
       " 'sup_soljanka_mal']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\m.lavreniuk\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: jdcal in c:\\users\\m.lavreniuk\\anaconda3\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\m.lavreniuk\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "df.to_excel('./sku.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
